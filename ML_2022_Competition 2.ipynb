{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2f8714-a25d-4393-95df-5a6f896b346e",
   "metadata": {},
   "source": [
    "# Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a3894-2de0-4cab-9fa5-3bb8d2793026",
   "metadata": {},
   "source": [
    "# Task Overview\n",
    "You are given a dataset of images and descriptions for 200 categories of birds, as you could see in Assignment 2.\n",
    "\n",
    "Download the data from [competition page](https://www.kaggle.com/t/7aeb373db52b4355bcdb3daed8e6586f). This is also where you will upload your submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d396cc-65e7-48a9-92d9-1a231e244d8d",
   "metadata": {},
   "source": [
    "You need to improve the accuracy of the model as much as you can.\n",
    "\n",
    "## Rules:\n",
    "1. Do not use any external data **NOR** models pre-trained on other datasets\n",
    "2. Use the test set **ONLY** to get predictions for your model. For example, do not use it to compute statistics or features (e.g. learning preprocessing).\n",
    "3. Do not use deep learning models for a fair competition\n",
    "4. Don't cheat :)\n",
    "\n",
    "## Hints\n",
    "Here are several techniques that you can use:\n",
    "\n",
    "1) **Tune your hyper-parameters.** Try *GridSerachCV* function from *sklearn.model_selection* to find the best set of hyperparameters.\n",
    "\n",
    "2) **Data pre-processing and post-processing.** In the example, we treated each caption as a different data sample. Are there any other ways to use the captions? As post-processing, we used majority voting. An alternative would be to take the most confident caption prediction (using _predict_proba_ method of the classifier, that returns probabilities)\n",
    "\n",
    "3) **Feature engineering.** Play with the representation of the textual data. We only tried one, but there are more (e.g. TF-IDF Vectorizer is another powerful method to transform text to a vector, taking into account the rareness of the words across the texts). Also do not hesitate to play with the arguments of the *Vectorizers*. \n",
    "\n",
    "4) **Change your model.** You are not restricted to train *Naive Bayes* only. You can use whatever algorithm you're already familiar with. Moreover, you can use the algorithms that you get to know during these 3 weeks of solving this assignment. E.g. give *RandomForests* a try!\n",
    "\n",
    "5) **Use image data.** The dataset consists not only of captions, but also images. You've seen examples how classifiers can be trained on images. This dataset, however, is more challenging, since the objects are not aligned. Using raw pixels might be too challenging (but not useless - give it a try!) for the classifiers we learn in class; however, there are number of methods that allow to extract image descriptors that might be better suited. Color histogram is one example. You might want to explore different types of pre-processing as well (e.g., taking image crops)\n",
    "\n",
    "6) **Combine multiple models.** You can train multiple models (uni- or multimodal) and use their individual predictions to produce a final, improved prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342cac2c-8ecf-4d46-a38b-97c93dfbac31",
   "metadata": {},
   "source": [
    "## Scoring rules [15 points + 20 bonus points]\n",
    "You have until **14.12.2022** to submit your tuned solutions.  \n",
    "**You also need to submit the code for your best solution before the deadline.**\n",
    "\n",
    "### **Part of the Assignment grade: [15 points]**\n",
    "You need to beat two thresholds in order to get a full set of points for the assignment:\n",
    "\n",
    "- You get **5 points** if you get at least 45% on the public board\n",
    "\n",
    "- You get another **10 points** if you beat the **hard baseline** - 55.316%. This is the score of the hidden classifier that is trained by TAs, you don't have access to its code.  \n",
    "*Hint: It's a rather minor change from the simple baseline*\n",
    "\n",
    "### **Bonus points [up to 20 points]**\n",
    "- **Top-5** on the final leaderboard get **20 bonus points**\n",
    "\n",
    "- **Top-10** on the final leaderboard get **15 bonus points**\n",
    "\n",
    "- **Top-15** on the final leaderboard get **10 bonus points**\n",
    "\n",
    "- **Top-25** on the final leaderboard get **5 bonus points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87b993d-9b45-47da-9d3a-6942c15e7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to improve! The assignment 2 code should get you started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e25c666-a005-4485-9e72-59cd7cb4ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "\n",
    "dataset_train = pd.read_csv('train_dataframe_sorted.csv')\n",
    "dataset_test = pd.read_csv('test_dataframe_obfuscated_nolabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1882f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_string = \"\"\n",
    "for idx in range(len(dataset_test)):\n",
    "    combined_descriptions = \"\"\n",
    "    for caption_label in [f'caption_{i}' for i in range(1, 11)]:\n",
    "        combined_descriptions+=\" \"+dataset_test[caption_label][idx]\n",
    "    long_string+=combined_descriptions\n",
    "    \n",
    "    \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "s = vectorizer.get_stop_words()\n",
    "\n",
    "words = long_string.replace(\",\",\" \").replace(\".\",\" \").split(\" \")\n",
    "words_2 = []\n",
    "for i in words:\n",
    "    if not i in s and not i==\"\":\n",
    "        words_2.append(i)\n",
    "words = words_2\n",
    "\n",
    "countlst = {}\n",
    "for i in words:\n",
    "    if i in countlst.keys():\n",
    "        countlst[i]+=1\n",
    "    else:\n",
    "        countlst[i]=1\n",
    "        \n",
    "sorted_dict = {}\n",
    "top_words = sorted(countlst, key=countlst.get, reverse=True)[:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524a32db-dd34-40c3-b238-6ee4f3993115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "# you might want to work with smaller images (but use them as you please)\n",
    "def read_image(impath, size=((10,10))):\n",
    "    img = np.array(Image.open(impath).resize(size))\n",
    "    return np.array(img)\n",
    "\n",
    "def convert_bw_to_col(img):\n",
    "    out=[]\n",
    "    for i in img:\n",
    "        row = []\n",
    "        for j in i:\n",
    "            row.append([j,j,j])\n",
    "        out.append(row)\n",
    "    return np.array(out)\n",
    "\n",
    "def check_if_bw(img):\n",
    "    if np.array(img).shape == (len(img),len(img[0])):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_col_image(img):\n",
    "    if check_if_bw(img):\n",
    "        return convert_bw_to_col(img)\n",
    "    else:\n",
    "        return img\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c4c8af0-ad59-4d8f-a99d-ae817fda6621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAoAAAAKCAIAAAACUFjqAAAA6klEQVR4nAXBvU4CURgE0JnLrqHQTgJiYoOdFmDgkW2tgDdAH4FYWYiJCSbIz8K63G/Gc3g4HgwbhF2WZc4BGyAAIiUgCCWrLFqz6ayq9iRswTIi0STQbl8sXt/m82n7ogQCzrYgJUuQ16vPxctztVm/L5fKWQpFjjgXOgeJ79XXz3bX79/e9HqRs2EYAAspA3h8mjwMx2U+dbudY1UZtgkgSSHF6VSNJ5P9x3K32diwZIUVSaGI3Jz/7gb3V9ed3fbXdoRDDrlomtoA6ZRaw9EwEU1TyzZIoKiPNQkTJC8HI7OojyeQQAvwPyhsqWBprvZxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=10x10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(read_image(dataset_train['impath'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "996d380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_train, val_split = train_test_split(dataset_train, test_size=0.1, random_state=22)\n",
    "dataset_train = dataset_train.reset_index()\n",
    "val_split = val_split.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cc61a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats as st\n",
    "def convert_to_sample_prediction(predictions):\n",
    "    '''\n",
    "    Takes per-caption predictions of shape (10n,)\n",
    "    Should return per-sample predictions of shape (n,)\n",
    "    '''\n",
    "    predictions = predictions.reshape(-1, 10) # now we have a matrix of N_samples x 10 predictions\n",
    "\n",
    "    ### TODO: For each prediction row, return the most common one. You can use scipy.stats.mode function [2 pt]\n",
    "    predictions = st.mode(predictions, axis=1).mode\n",
    "    ### End of your code\n",
    "    return predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8125f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO: Data preprocessing on the train set - converting the dataset into (caption, label) pairs\n",
    "#### Data preprocessing on the test set -- the test set doesn't have labels this time\n",
    "\n",
    "\n",
    "\n",
    "train_caption_labels = {'caption': [], 'label': []}\n",
    "for idx in range(len(dataset_train)):\n",
    "    combined_descriptions = \"\"\n",
    "    label_appended = False\n",
    "    for caption_label in [f'caption_{i}' for i in range(1, 11)]:\n",
    "        if(not label_appended):\n",
    "            train_caption_labels['label'].append(dataset_train['label'][idx])\n",
    "            label_appended = True\n",
    "        combined_descriptions+=\" \"+dataset_train[caption_label][idx]\n",
    "    train_caption_labels['caption'].append(combined_descriptions)\n",
    "    \n",
    "validation_caption_labels = {'caption': [], 'label': []}\n",
    "for idx in range(len(val_split)):\n",
    "    combined_descriptions = \"\"\n",
    "    label_appended = False\n",
    "    for caption_label in [f'caption_{i}' for i in range(1, 11)]:\n",
    "        if(not label_appended):\n",
    "            validation_caption_labels['label'].append(val_split['label'][idx])\n",
    "            label_appended = True\n",
    "        combined_descriptions+=\" \"+val_split[caption_label][idx]\n",
    "    validation_caption_labels['caption'].append(combined_descriptions)\n",
    "    \n",
    "        \n",
    "test_caption_labels = {'caption': []}\n",
    "for idx in range(len(dataset_test)):\n",
    "    combined_descriptions = \"\"\n",
    "    for caption_label in [f'caption_{i}' for i in range(1, 11)]:\n",
    "        combined_descriptions+=\" \"+dataset_test[caption_label][idx]\n",
    "    test_caption_labels['caption'].append(combined_descriptions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b4d4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_labels = {'image': [], 'label': []}\n",
    "for idx in range(len(dataset_train)):\n",
    "    train_image_labels['label'].append(dataset_train['label'][idx])\n",
    "    image =  get_col_image(read_image(dataset_train['impath'][idx]))\n",
    "    hist = image.flatten()\n",
    "    #hist = np.array([np.histogram(image[:, :, i], bins=500, range=(0, 256))[0] for i in range(3)]).flatten()\n",
    "    train_image_labels['image'].append(hist)\n",
    "    \n",
    "validation_image_labels = {'image': [], 'label': []}\n",
    "for idx in range(len(val_split)):\n",
    "    validation_image_labels['label'].append(val_split['label'][idx])\n",
    "    image =  get_col_image(read_image(val_split['impath'][idx]))\n",
    "    hist = image.flatten()\n",
    "    #hist = np.array([np.histogram(image[:, :, i], bins=500, range=(0, 256))[0] for i in range(3)]).flatten()\n",
    "    validation_image_labels['image'].append(hist)\n",
    "\n",
    "        \n",
    "test_image_labels = {'image': []}\n",
    "for idx in range(len(dataset_test)):\n",
    "    image =  get_col_image(read_image(dataset_test['impath'][idx]))\n",
    "    #hist = np.array([np.histogram(image[:, :, i], bins=500, range=(0, 256))[0] for i in range(3)]).flatten()\n",
    "    hist = image.flatten()\n",
    "    test_image_labels['image'].append(hist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10127ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_labels_df = pd.DataFrame(train_image_labels)\n",
    "validation_image_labels_df = pd.DataFrame(validation_image_labels)\n",
    "test_image_labels_df = pd.DataFrame(test_image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50752415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "image_train_target = train_image_labels[\"label\"]\n",
    "image_train_feautures = train_image_labels[\"image\"]\n",
    "\n",
    "img_clf = MultinomialNB()\n",
    "\n",
    "img_clf.fit(image_train_feautures, image_train_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f97d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = {\"caption\":[], \"label\":[]}\n",
    "\n",
    "import random\n",
    "\n",
    "#### generating more training data by combining captions of different existing ones\n",
    "#1. sorting the samples into pools according to their label\n",
    "\n",
    "pools = []\n",
    "for i in range(200):\n",
    "    pools.append([])\n",
    "    \n",
    "for i in range(len(dataset_train)):\n",
    "    sample = []\n",
    "    for j in range(1,11):\n",
    "        sample.append(dataset_train[\"caption_\"+str(j)][i])\n",
    "    pools[dataset_train[\"label\"][i]].append(sample)\n",
    "    \n",
    "def generate_samples_for_class(amount, cls=0):\n",
    "    #2. adding more samples for each label\n",
    "    amt_of_new_sample_per_label=amount\n",
    "    out = []\n",
    "    i=cls\n",
    "    for k in range(amt_of_new_sample_per_label):\n",
    "        new_sample = \"\"\n",
    "        for j in range(10):\n",
    "            rand_sample = pools[i][random.randint(0,len(pools[i])-1)]\n",
    "            rand_caption = rand_sample[random.randint(0,len(rand_sample)-1)]\n",
    "            new_sample+=rand_caption\n",
    "        out.append(new_sample)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a9d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_set_labels_df = pd.DataFrame(val_set[\"label\"])\n",
    "val_set_captions_df = pd.DataFrame(val_set[\"caption\"])\n",
    "\n",
    "train_caption_labels_df = pd.DataFrame(train_caption_labels)\n",
    "validation_caption_labels_df = pd.DataFrame(validation_caption_labels)\n",
    "test_caption_labels_df = pd.DataFrame(test_caption_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e58606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO: Text preprocessing - fitting the vectorizer on the train set\n",
    "#Creating the vectorizer with the appropriate stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "s_words = set()\n",
    "for i in vectorizer.get_stop_words():\n",
    "    s_words.add(i)\n",
    "irrelevant_words = [\"bird\"]\n",
    "for i in irrelevant_words:\n",
    "    s_words.add(i)  \n",
    "vectorizer = CountVectorizer(ngram_range=(1,2),stop_words=s_words, min_df=11)\n",
    "\n",
    "\n",
    "vectorizer.fit(train_caption_labels_df['caption'].values) # We should only use train data for pre-processing\n",
    "train_caption_features = vectorizer.transform(train_caption_labels_df['caption'].values)\n",
    "target_train = train_caption_labels_df['label']\n",
    "\n",
    "validation_caption_features = vectorizer.transform(validation_caption_labels_df['caption'])\n",
    "val_caption_features = vectorizer.transform(val_set[\"caption\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a0d23",
   "metadata": {},
   "source": [
    "My approach for the main classifyer is a voting classifyer, so an ensemble where the decisions is formed by aggregating the decisions of multiple MultinomialNB with different alphas. The aggregation is weighted according to the confidence of the classifyer.\n",
    "\n",
    "(I tried many other approaches with different ensembles, boosting and different base classifyers, but this is the one that performed the best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de946fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;clf1&#x27;, MultinomialNB()),\n",
       "                             (&#x27;clf2&#x27;, MultinomialNB(alpha=0.55)),\n",
       "                             (&#x27;clf3&#x27;, MultinomialNB(alpha=0.4)),\n",
       "                             (&#x27;clf4&#x27;, MultinomialNB(alpha=0.325)),\n",
       "                             (&#x27;clf5&#x27;, MultinomialNB(alpha=0.28)),\n",
       "                             (&#x27;clf6&#x27;, MultinomialNB(alpha=0.25)),\n",
       "                             (&#x27;clf7&#x27;, MultinomialNB(alpha=0.2285714285714286)),\n",
       "                             (&#x27;clf8&#x27;, MultinomialNB(alpha=0.21250000000000002)),\n",
       "                             (&#x27;clf9&#x27;, MultinomialNB(alpha=0.2)),\n",
       "                             (&#x27;clf10&#x27;, MultinomialNB(alpha=0.19)),\n",
       "                             (&#x27;clf12&#x27;, MultinomialNB(alpha=0.75))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;clf1&#x27;, MultinomialNB()),\n",
       "                             (&#x27;clf2&#x27;, MultinomialNB(alpha=0.55)),\n",
       "                             (&#x27;clf3&#x27;, MultinomialNB(alpha=0.4)),\n",
       "                             (&#x27;clf4&#x27;, MultinomialNB(alpha=0.325)),\n",
       "                             (&#x27;clf5&#x27;, MultinomialNB(alpha=0.28)),\n",
       "                             (&#x27;clf6&#x27;, MultinomialNB(alpha=0.25)),\n",
       "                             (&#x27;clf7&#x27;, MultinomialNB(alpha=0.2285714285714286)),\n",
       "                             (&#x27;clf8&#x27;, MultinomialNB(alpha=0.21250000000000002)),\n",
       "                             (&#x27;clf9&#x27;, MultinomialNB(alpha=0.2)),\n",
       "                             (&#x27;clf10&#x27;, MultinomialNB(alpha=0.19)),\n",
       "                             (&#x27;clf12&#x27;, MultinomialNB(alpha=0.75))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clf1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clf2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.55)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clf3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.4)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clf4</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.325)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clf5</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.28)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clf6</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.25)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clf7</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.2285714285714286)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clf8</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.21250000000000002)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clf9</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.2)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clf10</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.19)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clf12</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.75)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('clf1', MultinomialNB()),\n",
       "                             ('clf2', MultinomialNB(alpha=0.55)),\n",
       "                             ('clf3', MultinomialNB(alpha=0.4)),\n",
       "                             ('clf4', MultinomialNB(alpha=0.325)),\n",
       "                             ('clf5', MultinomialNB(alpha=0.28)),\n",
       "                             ('clf6', MultinomialNB(alpha=0.25)),\n",
       "                             ('clf7', MultinomialNB(alpha=0.2285714285714286)),\n",
       "                             ('clf8', MultinomialNB(alpha=0.21250000000000002)),\n",
       "                             ('clf9', MultinomialNB(alpha=0.2)),\n",
       "                             ('clf10', MultinomialNB(alpha=0.19)),\n",
       "                             ('clf12', MultinomialNB(alpha=0.75))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### TODO: Train the model on the train set\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "clf1 = MultinomialNB(alpha = 0.75)\n",
    "clf2 = RandomForestClassifier(3000)\n",
    "clf3 = SGDClassifier( loss=\"log_loss\", penalty='l2')\n",
    "\n",
    "text_classifiers = [(\"Multinomial Naive Bayes\", clf1),\n",
    "                        (\"Random Forest\", clf2),\n",
    "                        (\"SVM classifier\", clf3)]\n",
    "\n",
    "text_classifiers= []\n",
    "for i in range(1,11):\n",
    "    text_classifiers.append((\"clf\"+str(i),MultinomialNB(alpha = (0.1+0.9/i))))\n",
    "\n",
    "text_classifiers.append((\"clf12\",clf1))\n",
    "\n",
    "\n",
    "clf = VotingClassifier(text_classifiers, voting=\"soft\")\n",
    "\n",
    "clf.fit(train_caption_features, target_train)\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "#                         END OF YOUR CODE                            #\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa08fd",
   "metadata": {},
   "source": [
    "#### Moddifyling with binary classifyers\n",
    "The idea here stems from the fact that in 40% of the mistakes that the classifyer makes, the second most confident guess would have been the right one. So i'm trying to get a signal to decide when to use the second (or even third and so on) most confident guess. This is done with the help of 200 binary classifyers which can only distinguish between one class and all the other birds. I hope that this results in the binary classifyers being able to spot mistakes that the main classifyer makes, especially since they are two different models (the binary classifyers are passive agressive classifyers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dad1cd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                                                | 50%                                             | 100%\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||"
     ]
    }
   ],
   "source": [
    "### create 200 models that make binary distinction, where the i-th classifier distingushes between the i-th bird kind and all the other kinds\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "add_more_data = True\n",
    "binary_clfs = []\n",
    "print(\"|\", end=\"\")\n",
    "for i in range(48):\n",
    "    print(\" \", end=\"\")\n",
    "print(\"| 50%\", end=\"\")\n",
    "for i in range(45):\n",
    "    print(\" \", end=\"\")\n",
    "print(\"| 100%\")\n",
    "for i in range(200):\n",
    "    if i%2 ==0:\n",
    "        print(\"|\", end=\"\")\n",
    "        #print(str(i)+\" binary classifiers fitted\")\n",
    "    labels = []\n",
    "    for j in target_train:\n",
    "        if j == i:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    if add_more_data:\n",
    "        new_samples = generate_samples_for_class(100, cls = i)\n",
    "        temp_training_set = [i for i in train_caption_labels[\"caption\"]]\n",
    "        for sample in new_samples:\n",
    "            temp_training_set.append(sample)\n",
    "            labels.append(1)\n",
    "        x = np.array(temp_training_set)\n",
    "        temp_feautures = vectorizer.transform(x)\n",
    "        binary_clf = PassiveAggressiveClassifier(C=0.001)\n",
    "        binary_clf.fit(temp_feautures, labels)\n",
    "    else:\n",
    "        binary_clf = PassiveAggressiveClassifier(C=0.74)\n",
    "        binary_clf.fit(train_caption_features, labels)\n",
    "    binary_clfs.append(binary_clf)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff2575d",
   "metadata": {},
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha = 0.04)\n",
    "clf.fit(train_caption_features, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "812538e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO: Vectorize the test set and run the prediction on the test set\n",
    "test_caption_features = vectorizer.transform(test_caption_labels_df['caption'].values)\n",
    "predictions_test = clf.predict(test_caption_features)\n",
    "predictions_validation = clf.predict(validation_caption_features)\n",
    "predictions_train = clf.predict(train_caption_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "039e60e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train per-sample accuracy: 0.977\n",
      "actual validation set per-sample accuracy: 0.658\n"
     ]
    }
   ],
   "source": [
    "#### TODO: Convert the per-caption prediction to per-sample predictions. [1 pt]\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#train_sample_predictions = convert_to_sample_prediction(predictions_train)\n",
    "#test_sample_predictions = convert_to_sample_prediction(predictions_test)\n",
    "\n",
    "train_sample_labels = train_caption_labels_df['label']\n",
    "val_set_labels = val_set[\"label\"]\n",
    "validation_set_labels = validation_caption_labels[\"label\"]\n",
    "#### TODO: Report the train accuracy (should be around 55%)\n",
    "\n",
    "train_accuracy = accuracy_score(predictions_train, train_sample_labels)\n",
    "print(f\"Train per-sample accuracy: {train_accuracy:.3f}\")\n",
    "if(len(val_set[\"caption\"])>0):\n",
    "    val_accuracy = accuracy_score(clf.predict(val_caption_features), val_set_labels)\n",
    "    print(f\"val per-sample accuracy: {val_accuracy:.3f}\")\n",
    "val_accuracy = accuracy_score(predictions_validation, validation_set_labels)\n",
    "print(f\"actual validation set per-sample accuracy: {val_accuracy:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "train_image_prediction = img_clf.predict(train_image_labels[\"image\"])\n",
    "test_image_prediction = img_clf.predict(test_image_labels[\"image\"])\n",
    "validation_image_prediction = img_clf.predict(validation_image_labels[\"image\"])\n",
    "\n",
    "\n",
    "img_accuracy_train = accuracy_score(train_image_prediction, train_image_labels[\"label\"])\n",
    "img_accuracy_validation = accuracy_score(validation_image_prediction, validation_image_labels[\"label\"])\n",
    "if(False):\n",
    "    print(\"image accuracy train:\", img_accuracy_train)\n",
    "    print(\"image accuracy validation:\", img_accuracy_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a5c016fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of classifications unconfirmed by the binary classifiers 0.4181636726546906\n",
      "validation accuracy with binary classifiers: 0.6656686626746507\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def second_highest_index(lst):\n",
    "    copy = [i for i in lst]\n",
    "    m = max(copy)\n",
    "    for i in range(len(copy)):\n",
    "        if copy[i]==m:\n",
    "            copy[i]=0\n",
    "            break\n",
    "    return np.argmax(copy)\n",
    "\n",
    "def nth_highest_index(n, lst):\n",
    "    copy = [(i,lst[i]) for i in range(len(lst))]\n",
    "    copy.sort(key=lambda y: y[1], reverse=True)    \n",
    "    return copy[n-1][0]\n",
    "\n",
    "\n",
    "confidences_captions_train = clf.predict_proba(train_caption_features)\n",
    "confidences_captions_validation = clf.predict_proba(validation_caption_features)\n",
    "confidences_captions_test = clf.predict_proba(test_caption_features)\n",
    "\n",
    "final_predictions = []\n",
    "final_predictions_test = []\n",
    "unconfirmed_decisions = 0;   \n",
    "\n",
    "for i in range(len(confidences_captions_validation)):\n",
    "    \n",
    "    found = False\n",
    "    pred = np.argmax(confidences_captions_validation[i])\n",
    "    for j in range(2,20):\n",
    "        if binary_clfs[pred].predict(validation_caption_features)[i]==0:\n",
    "            pred = nth_highest_index(j,confidences_captions_validation[i])\n",
    "        else:\n",
    "            found = True\n",
    "            #if(j>2):\n",
    "                #print(\"found!\")\n",
    "            break\n",
    "    \n",
    "    if not found:\n",
    "        pred = np.argmax(confidences_captions_validation[i])        \n",
    "        unconfirmed_decisions+=1\n",
    "    #if(pred != np.argmax(confidences_captions_validation[i])):\n",
    "        #print(\"changed\")\n",
    "    final_predictions.append(pred)\n",
    "    \n",
    "print(\"ratio of classifications unconfirmed by the binary classifiers\",unconfirmed_decisions/len(confidences_captions_validation))\n",
    "    \n",
    "for i in range(len(confidences_captions_test)):\n",
    "    found = False\n",
    "    pred = np.argmax(confidences_captions_test[i]) \n",
    "    for j in range(2,20):\n",
    "        if binary_clfs[pred].predict(test_caption_features)[i]==0:\n",
    "            pred = nth_highest_index(j,confidences_captions_test[i])\n",
    "        else:\n",
    "            found = True\n",
    "            #if(j>2):\n",
    "                #print(\"found!\")\n",
    "            break\n",
    "            \n",
    "    if not found:\n",
    "        pred = np.argmax(confidences_captions_test[i])\n",
    "        \n",
    "    #if(pred != np.argmax(confidences_captions_test[i])):\n",
    "        #print(\"changed\")\n",
    "    \n",
    "    final_predictions_test.append(pred)\n",
    "    \n",
    "val_accuracy = accuracy_score(final_predictions, validation_set_labels)\n",
    "print(\"validation accuracy with binary classifiers:\",val_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "337035e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    results = []\n",
    "    for i in range(1,1):\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,2),stop_words=s_words, min_df=i)\n",
    "\n",
    "\n",
    "        vectorizer.fit(train_caption_labels_df['caption'].values) # We should only use train data for pre-processing\n",
    "        train_caption_features = vectorizer.transform(train_caption_labels_df['caption'].values)\n",
    "        target_train = train_caption_labels_df['label']\n",
    "\n",
    "        validation_caption_features = vectorizer.transform(validation_caption_labels_df['caption'])\n",
    "        val_caption_features = vectorizer.transform(val_set[\"caption\"])\n",
    "\n",
    "        clf.fit(train_caption_features, target_train)\n",
    "\n",
    "        test_caption_features = vectorizer.transform(test_caption_labels_df['caption'].values)\n",
    "        predictions_test = clf.predict(test_caption_features)\n",
    "        predictions_validation = clf.predict(validation_caption_features)\n",
    "        predictions_train = clf.predict(train_caption_features)\n",
    "\n",
    "        train_sample_labels = train_caption_labels_df['label']\n",
    "        val_set_labels = val_set[\"label\"]\n",
    "        validation_set_labels = validation_caption_labels[\"label\"]\n",
    "        #### TODO: Report the train accuracy (should be around 55%)\n",
    "\n",
    "        val_accuracy = accuracy_score(predictions_validation, validation_set_labels)\n",
    "        print(f\"validation accuracy for min_df = {i}: {val_accuracy}\")\n",
    "        results.append(val_accuracy)\n",
    "    print(\"maximales min_df\",np.argmax(results)+1)\n",
    "    print(max(results))\n",
    "    plt.plot(results)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "06ba0e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save the prediction in the submission format and upload to Kaggle!\n",
    "\n",
    "########################################################################\n",
    "#                                                                      #\n",
    "# Create a submission DataFrame that has two columns: id and prediction#\n",
    "# with the predicted label.                                            #\n",
    "#                                                                      #\n",
    "########################################################################\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {\"id\": dataset_test['sample_id'],\n",
    "     \"prediction\": final_predictions_test})\n",
    "\n",
    "\n",
    "### Save the submission and TODO: upload to Kaggle!\n",
    "submission.to_csv(\"simple_baseline.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410749a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
